
# Generative-Art-Research
Neural networks to extract mid-level such as roundness, or messiness from images, especially abstract images. Training is done on a controlled set of generated images with continuous levels of these parameters.

- **Abstract-Feature-Recognition** contains the training, testing, and predicted code as well as helper files
- **Processing Sketches** Contains the Processing scripts used to generate the training images

## How to Train
Use **Parameters_Train.py**
### Get Images
The images should be in the format **img-c##-r##-###.png**
The first three letters, **img** are the type of the image. Images generated by the same script should have the same type.
Each parameter **-c##** is designated by a dash followed by a letter. *c* might be *curliness.*
At the end is a string of numbers, **###**, used to keep multiple images with the same parameter values unique.

The data used for the project during J-term is stored on basin, here:
http://www.cs.middlebury.edu/~hgoudey/Generative-Art-Research-Data/

The processing scripts in the repository could also just be run to generate the images again from scratch.

### Train on the image set
Run the python file Parameters.py like this:

    python3 Parameters.py train IMAGE_DIR -l MODEL_TO_LOAD -n RUN_ID -e EPOCHS -t IMAGE_TYPES -m PARAMETER_MAP

 - **IMAGE_DIR (required):** The directory to load the images from
 - **MODEL_TO_LOAD (-l):** If this field is specified, the program will look in the folder provided and start the training with the model loaded from there.
 - **RUN_ID (-n):** The results will be saved in a folder with this name. If this is not specified, a name will be created based on other information.
 - **EPOCHS (-e):** The number of epochs to train on the data


The number and letters of the parameters are gathered from the first image the script reads, so it assumes uniformity of the images in the IMAGE_DIR.

Change the output folder. The folder name is automatically created from these parameters:

    N_EPOCHS = 1
    RUN_ID = 302

The PARAMETER_MAP variable is used to make one parameter equivalent to another. Just add another element to the dictionary to collapse two parameters. 

## How to Predict
Use **Parameters_Predict.py**
### Remove Junk Images
Using a Firefox extension to download Google Images search results, I ended up with quite a few images that my script can't open. If the quality of the images is unknown, it would be worth it to run the **Remove_Bad_Images.py** script on the directory first.
### Change Prediction Run Data
Change the directory of the image data, and the directory that the model will be loaded from. The model h5 file and the Parameters.pickle file which stores the parameters used for training that model should be stored in the model directory.

    IMAGE_DIR = "E:\\Generative-Art-Research\\Images\\Messy Round Rects"
    
    MODEL_DIR = "E:\\Generative-Art-Research\\Abstract-Feature-Extraction\\Run 302 Results 1 Epochs"
### Run the Python File
The results of the training run will be stored in the same directory that the model comes from

## How to Test
The testing script is still being converted to use multiple parameters. The current script, **Parameters_Test.py** will only work with models created with the single-parameter training script, **Parameter_Train.py** (no "s").

# TO DO
- Create rounded rectangle images with no fill.
- Iterate on the network. Will smaller convolution filters from the start work as well? Explore more hyper-parameters.
- Symmetry Parameter
- Repetition Parameter
- Blur Parameter
- Try three parameters in one model.. four possibly?
- More... I will add to this list
